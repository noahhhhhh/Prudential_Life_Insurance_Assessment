# [31] "Insurance_History_2"              "Insurance_History_3"
# [33] "Insurance_History_4"              "Insurance_History_5_Impute_1"
# [35] "Insurance_History_5_Impute_Mean"  "Insurance_History_7"
# [37] "Insurance_History_8"              "Insurance_History_9"
# [39] "Insurance_History_Num_of_NAs"     "InsuredInfo_1"
# [41] "InsuredInfo_2"                    "InsuredInfo_3_bin_1"
# [43] "InsuredInfo_3_bin_2"              "InsuredInfo_3_bin_3"
# [45] "InsuredInfo_3_bin_4"              "InsuredInfo_4"
# [47] "InsuredInfo_5"                    "InsuredInfo_6"
# [49] "InsuredInfo_7"                    "isTest"
# [51] "Medical_History_1_Impute_2016"    "Medical_History_1_Impute_Median"
# [53] "Medical_History_11"               "Medical_History_12"
# [55] "Medical_History_13"               "Medical_History_14"
# [57] "Medical_History_15_Impute_2016"   "Medical_History_15_Impute_Median"
# [59] "Medical_History_16"               "Medical_History_17"
# [61] "Medical_History_18"               "Medical_History_19"
# [63] "Medical_History_2_bin_1"          "Medical_History_2_bin_10"
# [65] "Medical_History_2_bin_2"          "Medical_History_2_bin_3"
# [67] "Medical_History_2_bin_4"          "Medical_History_2_bin_5"
# [69] "Medical_History_2_bin_6"          "Medical_History_2_bin_7"
# [71] "Medical_History_2_bin_8"          "Medical_History_2_bin_9"
# [73] "Medical_History_20"               "Medical_History_21"
# [75] "Medical_History_22"               "Medical_History_23"
# [77] "Medical_History_25"               "Medical_History_26"
# [79] "Medical_History_27"               "Medical_History_28"
# [81] "Medical_History_29"               "Medical_History_3"
# [83] "Medical_History_30"               "Medical_History_31"
# [85] "Medical_History_33"               "Medical_History_34"
# [87] "Medical_History_35"               "Medical_History_36"
# [89] "Medical_History_37"               "Medical_History_38"
# [91] "Medical_History_39"               "Medical_History_4"
# [93] "Medical_History_40"               "Medical_History_41"
# [95] "Medical_History_5"                "Medical_History_6"
# [97] "Medical_History_7"                "Medical_History_8"
# [99] "Medical_History_9"                "Medical_History_Num_of_NAs"
# [101] "Medical_Keyword_1"                "Medical_Keyword_10"
# [103] "Medical_Keyword_11"               "Medical_Keyword_12"
# [105] "Medical_Keyword_13"               "Medical_Keyword_14"
# [107] "Medical_Keyword_15"               "Medical_Keyword_16"
# [109] "Medical_Keyword_17"               "Medical_Keyword_18"
# [111] "Medical_Keyword_19"               "Medical_Keyword_2"
# [113] "Medical_Keyword_20"               "Medical_Keyword_21"
# [115] "Medical_Keyword_22"               "Medical_Keyword_23"
# [117] "Medical_Keyword_24"               "Medical_Keyword_25"
# [119] "Medical_Keyword_26"               "Medical_Keyword_27"
# [121] "Medical_Keyword_28"               "Medical_Keyword_29"
# [123] "Medical_Keyword_3"                "Medical_Keyword_30"
# [125] "Medical_Keyword_31"               "Medical_Keyword_32"
# [127] "Medical_Keyword_33"               "Medical_Keyword_34"
# [129] "Medical_Keyword_35"               "Medical_Keyword_36"
# [131] "Medical_Keyword_37"               "Medical_Keyword_38"
# [133] "Medical_Keyword_39"               "Medical_Keyword_4"
# [135] "Medical_Keyword_40"               "Medical_Keyword_41"
# [137] "Medical_Keyword_42"               "Medical_Keyword_43"
# [139] "Medical_Keyword_44"               "Medical_Keyword_45"
# [141] "Medical_Keyword_46"               "Medical_Keyword_47"
# [143] "Medical_Keyword_48"               "Medical_Keyword_5"
# [145] "Medical_Keyword_6"                "Medical_Keyword_7"
# [147] "Medical_Keyword_8"                "Medical_Keyword_9"
# [149] "Num_of_NAs"                       "Product_Info_1"
# [151] "Product_Info_2_1"                 "Product_Info_2_A"
# [153] "Product_Info_2_B"                 "Product_Info_2_bin_1"
# [155] "Product_Info_2_bin_2"             "Product_Info_2_bin_3"
# [157] "Product_Info_2_bin_4"             "Product_Info_2_bin_5"
# [159] "Product_Info_2_C"                 "Product_Info_2_D"
# [161] "Product_Info_2_E"                 "Product_Info_3_bin_1"
# [163] "Product_Info_3_bin_2"             "Product_Info_3_bin_3"
# [165] "Product_Info_3_bin_4"             "Product_Info_3_bin_5"
# [167] "Product_Info_3_bin_6"             "Product_Info_4"
# [169] "Product_Info_5"                   "Product_Info_6"
# [171] "Product_Info_7"                   "Response"
# [173] "Wt"
###################
## 1.4 class-ify ##
###################
# colNomial to factor
# previously forgot the medical_keyword, now add them in
colNominal <- c(colNominal, names(dt.imputed.combine)[grepl("Medical_Keyword", names(dt.imputed.combine))])
dt.imputed.combine.nominal <- dt.imputed.combine[, colNominal, with = F][, lapply(.SD, as.factor)]
dt.imputed.combine <- data.table(dt.imputed.combine[, !colNominal, with = F], dt.imputed.combine.nominal)
############################################################################################
## 2.0 save ################################################################################
############################################################################################
dt.class.ified.combine <- dt.imputed.combine
save(dt.class.ified.combine, colNominal, colDiscrete, colContinuous, file = "data/data_clean/dt_class_ified_combine.RData")
rm(list = ls()); gc();
setwd("/Volumes/Data Science/Google Drive/data_science_competition/kaggle/Prudential_Life_Insurance_Assessment/")
load("data/data_clean/dt_class_ified_combine.RData")
require(data.table)
############################################################################################
## 1.0 Age_Group ###########################################################################
############################################################################################
# 5 groups
dt.class.ified.combine[, Age_Group := as.factor(as.integer(cut2(dt.class.ified.combine$Ins_Age, cuts = c(0, .2, .4, .6, 1))))]
colNominal <- c(colNominal, "Age_Group")
# dt.class.ified.combine[, Ins_Age := NULL]
# colNominal <- colNominal[!colNominal %in% "Ins_Age"]
############################################################################################
## 2.0 Ht_Group ############################################################################
############################################################################################
# 5 groups
dt.class.ified.combine[, Ht_Group := as.factor(as.integer(cut2(dt.class.ified.combine$Ht, cuts = c(0, .2, .4, .6, 1))))]
colNominal <- c(colNominal, "Ht_Group")
# dt.class.ified.combine[, Ht := NULL]
# colNominal <- colNominal[!colNominal %in% "Ht"]
############################################################################################
## 3.0 Wt_Group ############################################################################
############################################################################################
# 5 groups
dt.class.ified.combine[, Wt_Group := as.factor(as.integer(cut2(dt.class.ified.combine$Wt, cuts = c(0, .2, .4, .6, 1))))]
colNominal <- c(colNominal, "Wt_Group")
# dt.class.ified.combine[, Wt := NULL]
# colNominal <- colNominal[!colNominal %in% "Wt"]
############################################################################################
## 4.0 BMI_Group ###########################################################################
############################################################################################
# 5 groups
dt.class.ified.combine[, BMI_Group := as.factor(as.integer(cut2(dt.class.ified.combine$BMI, cuts = c(0, .2, .4, .6, 1))))]
colNominal <- c(colNominal, "BMI_Group")
# dt.class.ified.combine[, BMI := NULL]
# colNominal <- colNominal[!colNominal %in% "BMI"]
############################################################################################
## 5.0 square, cube ########################################################################
############################################################################################
dt.class.ified.combine[, Ins_Age_2 := Ins_Age ^ 2]
dt.class.ified.combine[, Ht_2 := Ht ^ 2]
dt.class.ified.combine[, Wt_2 := Wt ^ 2]
dt.class.ified.combine[, BNI_2 := BMI ^ 2]
colContinuous <- c(colContinuous, "Ins_Age_2", "Ht_2", "Wt_2", "BNI_2")
dt.class.ified.combine[, Ins_Age_3 := Ins_Age ^ 3]
dt.class.ified.combine[, Ht_3 := Ht ^ 3]
dt.class.ified.combine[, Wt_3 := Wt ^ 3]
dt.class.ified.combine[, BNI_3 := BMI ^ 3]
colContinuous <- c(colContinuous, "Ins_Age_3", "Ht_3", "Wt_3", "BNI_3")
############################################################################################
## 6.0 BMI and Age #########################################################################
############################################################################################
dt.class.ified.combine[, Age_BMI := Ins_Age * BMI]
colContinuous <- c(colContinuous, "Age_BMI")
############################################################################################
## 7.0 Med_Keywords_Count ##################################################################
############################################################################################
colname.medKeywords <- names(dt.class.ified.combine)[grepl("Medical_Keyword_", names(dt.class.ified.combine))]
dt.medKeywords <- dt.class.ified.combine[, colname.medKeywords, with = F][, lapply(.SD, as.integer)]
dt.class.ified.combine[, Med_Keywords_Count := rowSums(dt.medKeywords) - 48]
colDiscrete <- c(colDiscrete, "Med_Keywords_Count")
############################################################################################
## 8.0 classDist ###########################################################################
############################################################################################
# mx.class.ified.combine <- data.matrix(dt.class.ified.combine[, !c("Id", "isTest", "Response"), with = F])[, -1]
# centroids <- classDist(mx.class.ified.combine, as.factor(dt.class.ified.combine$Response))
############################################################################################
## 9.0 t-sne ###############################################################################
############################################################################################
## scale
prep.class.ified.combine <- preProcess(dt.class.ified.combine[, !c("Id", "Response", "isTest"), with = F]
# , method = c("range")
, method = c("center", "scale")
, verbose = T)
dt.class.ified.combine.scale <- predict(prep.class.ified.combine, dt.class.ified.combine)
## t-sne
require(Rtsne)
mx.class.ified.combine.scale <- data.matrix(dt.class.ified.combine.scale[, !c("Id", "isTest", "Response"), with = F])
tsne.out <- Rtsne(mx.class.ified.combine.scale
, check_duplicates = F
, pca = F
, verbose = T
, perplexity = 30
, theta = .5
, dims = 2)
plot(tsne.out$Y, col = dt.class.ified.combine[dt.class.ified.combine$Response != 0]$Response)
mx.tsne.out <- tsne.out$Y
save(mx.tsne.out, file = "data/data_meta/dt_tsne.RData")
load("data/data_meta/dt_tsne.RData")
dt.class.ified.combine[, tsne_1 := mx.tsne.out[, 1]]
dt.class.ified.combine[, tsne_2 := mx.tsne.out[, 2]]
colContinuous <- c(colContinuous, "tsne_1", "tsne_2")
############################################################################################
## 9.0 save ################################################################################
############################################################################################
dt.featureEngineed.combine <- dt.class.ified.combine
save(dt.featureEngineed.combine, colNominal, colDiscrete, colContinuous, file = "data/data_enginee/dt_featureEngineed_combine.RData")
rm(list = ls()); gc();
setwd("/Volumes/Data Science/Google Drive/data_science_competition/kaggle/Prudential_Life_Insurance_Assessment/")
load("data/data_enginee/dt_featureEngineed_combine.RData")
require(data.table)
require(caret)
## 1.2 centre and scale ##
##########################
prep.class.ified.combine <- preProcess(dt.featureEngineed.combine[, !c("Id", "Response", "isTest"), with = F]
, method = c("range")
# , method = c("center", "scale")
, verbose = T)
dt.featureEngineed.combine <- predict(prep.class.ified.combine, dt.featureEngineed.combine)
dt.preprocessed.combine <- dt.featureEngineed.combine
save(dt.preprocessed.combine, colNominal, colDiscrete, colContinuous, file = "data/data_preprocess/dt_proprocess_combine.RData")
rm(list = ls()); gc();
setwd("/Volumes/Data Science/Google Drive/data_science_competition/kaggle/Prudential_Life_Insurance_Assessment/")
load("data/data_preprocess/dt_proprocess_combine.RData")
source("script/utilities/metrics.R")
source("script/utilities/preprocess.R")
require(data.table)
require(caret)
require(Metrics)
require(Hmisc)
############################################################################################
## 1.0 xgboost - gbtree ####################################################################
############################################################################################
################################
## 1.1 train, valid, and test ##
################################
require(xgboost)
require(Ckmeans.1d.dp)
cat("prepare train, valid, and test data set...\n")
set.seed(888)
ind.train <- createDataPartition(dt.preprocessed.combine[isTest == 0]$Response, p = .8, list = F) # remember to change it to .66
dt.train <- dt.preprocessed.combine[isTest == 0][ind.train]
dt.valid <- dt.preprocessed.combine[isTest == 0][-ind.train]
set.seed(888)
ind.valid <- createDataPartition(dt.valid$Response, p = .5, list = F)
dt.valid1 <- dt.valid[ind.valid]
dt.valid2 <- dt.valid[-ind.valid]
dt.test <- dt.preprocessed.combine[isTest == 1]
dim(dt.train); dim(dt.valid); dim(dt.test)
# apply noise on dt.train
# dim(dt.train)
# dt.train <- Noise(dt.train, noise_l = 0, noise_u = .00005, col_excl = c(colNominal, "Id", "Response", "isTest"))
# dim(dt.train)
x.train <- model.matrix(Response ~., dt.train[, !c("Id", "isTest"), with = F])[, -1]
# x.train <- data.matrix(dt.train[, !c("Id", "isTest", "Response"), with = F])
y.train <- dt.train$Response
dmx.train <- xgb.DMatrix(data =  x.train, label = y.train)
x.valid <- model.matrix(Response ~., dt.valid[, !c("Id", "isTest"), with = F])[, -1]
# x.valid <- data.matrix(dt.valid[, !c("Id", "isTest", "Response"), with = F])
y.valid <- dt.valid$Response
dmx.valid <- xgb.DMatrix(data =  x.valid, label = y.valid)
# x.valid1 <- model.matrix(Response ~., dt.valid1[, !c("Id", "isTest"), with = F])[, -1]
# y.valid1 <- dt.valid1$Response
# dmx.valid1 <- xgb.DMatrix(data =  x.valid1, label = y.valid1)
# x.valid2 <- model.matrix(Response ~., dt.valid2[, !c("Id", "isTest"), with = F])[, -1]
# y.valid2 <- dt.valid2$Response
# dmx.valid2 <- xgb.DMatrix(data =  x.valid2, label = y.valid2)
x.test <- model.matrix(~., dt.preprocessed.combine[isTest == 1, !c("Id", "isTest", "Response"), with = F])[, -1]
# x.test <- xgb.DMatrix(data = data.matrix(dt.test[, !c("Id", "isTest", "Response"), with = F]), label = rep(0, dim(dt.test)[1]))
################################
## 1.2 train ###################
################################
# m == 1; n == 2 produced the bset result
m <- 1; n <- 2
cat("creating 3 folds ...\n")
set.seed(888)
# create a 4 folds
folds <- createFolds(dt.train$Response, k = 3, list = F)
# reproduce with m = 1 and n = 2
cat("initiating variables ...\n")
ls.pred.train <- list()
ls.pred.valid <- list()
ls.pred.test <- list()
ls.pred.valid.op <- list()
ls.pred.test.op <- list()
ls.score <- list()
ls.optCuts <- list()
evalerror <- function(preds, dtrain){
labels <- getinfo(dtrain, "label")
err <- ScoreQuadraticWeightedKappa(labels,round(preds))
return(list(metric = "kappa", value = err))
}
cat("training ...\n")
for(s in 1:15){
# set up a score metric for folds
pred.train <- rep(0, dim(dt.train)[1])
pred.valid <- rep(0, dim(dt.valid)[1])
pred.test <- rep(0, dim(dt.test)[1])
# for(k in 1:3){ # folds
#         set.seed(m * 8 + n * 64 + k * 512 + s * 1024)
#         # dmx.train.fold
#         dt.train.fold <- dt.train[folds != k]
#         x.train.fold <- model.matrix(Response ~., dt.train.fold[, !c("Id", "isTest"), with = F])[, -1]
#         # x.train.fold <- data.matrix(dt.train.fold[, !c("Id", "isTest", "Response"), with = F])
#         y.train.fold <- dt.train.fold$Response
#         dmx.train.fold <- xgb.DMatrix(data =  x.train.fold, label = y.train.fold)
#         # dmx.valid.fold
#         dt.valid.fold <- dt.train[folds == k]
#         x.valid.fold <- model.matrix(Response ~., dt.valid.fold[, !c("Id", "isTest"), with = F])[, -1]
#         # x.valid.fold <- data.matrix(dt.valid.fold[, !c("Id", "isTest", "Response"), with = F])
#         y.valid.fold <- dt.valid.fold$Response
#         dmx.valid.fold <- xgb.DMatrix(data =  x.valid.fold, label = y.valid.fold)
# train
set.seed(m * 8 + n * 64 + s * 1024)
cv.xgb.out <- xgb.train(data = dmx.train
, booster = "gbtree"
, objective = "count:poisson"
# , objective = "reg:linear"
, params = list(nthread = 8
, eta = .025
, min_child_weight = 100
, max_depth = 8
, subsample = .8
, colsample_bytree = .8
# , metrics = "rmse"
)
, feval = evalerror #
, early.stop.round = 100
# , maximize = F
, maximize = T
, print.every.n = 150
, nrounds = 18000
, watchlist = list(valid = dmx.valid, train = dmx.train)
, verbose = T
)
pred.train <- predict(cv.xgb.out, dmx.train)
pred.valid <- predict(cv.xgb.out, dmx.valid)
pred.test <- predict(cv.xgb.out, x.test)
# }
#     pred.train <- pred.train / 3
#     pred.valid <- pred.valid / 3
#     pred.test <- pred.test / 3
set.seed(m * 8 + n * 64 + s * 1024)
trainForOpt <- sample(length(pred.train), length(pred.train) * .8)
pred.train.forOpt <- pred.train[trainForOpt]
cat("optimising the cuts on pred.train ...\n")
SQWKfun <- function(x = seq(1.5, 7.5, by = 1)){
cuts <- c(min(pred.train.forOpt), x[1], x[2], x[3], x[4], x[5], x[6], x[7], max(pred.train.forOpt))
pred <- as.integer(cut2(pred.train.forOpt, cuts))
err <- ScoreQuadraticWeightedKappa(pred, y.train[trainForOpt], 1, 8)
return(-err)
}
optCuts <- optim(seq(1.5, 7.5, by = 1), SQWKfun)
optCuts
cat("applying optCuts on valid ...\n")
cuts.valid <- c(min(pred.valid), optCuts$par, max(pred.valid))
pred.valid.op <- as.integer(cut2(pred.valid, cuts.valid))
print(paste("loop", s, ": valid score -", ScoreQuadraticWeightedKappa(y.valid, pred.valid.op)))
ls.score[[s]] <- ScoreQuadraticWeightedKappa(y.valid, pred.valid.op)
# [1] "loop 1 : valid score - 0.662693668247028" (-1 as impute)
# [1] "loop 1 : valid score - 0.664..." (-1 as impute plus all engineed features)
cat("applying optCuts on test ...\n")
cuts.test <- c(min(pred.test), optCuts$par, max(pred.test))
pred.test.op <- as.integer(cut2(pred.test, cuts.test))
cat("combining the optimised predictions ...\n")
ls.pred.train[[s]] <- pred.train
ls.pred.valid[[s]] <- pred.valid
ls.pred.test[[s]] <- pred.test
ls.pred.valid.op[[s]] <- pred.valid.op
ls.pred.test.op[[s]] <- pred.test.op
ls.optCuts[[s]] <- optCuts$par
}
cat("transform the train, valid, and test\n")
dt.pred.train <- as.data.table(sapply(ls.pred.train, print))
dt.pred.valid <- as.data.table(sapply(ls.pred.valid, print))
dt.pred.test <- as.data.table(sapply(ls.pred.test, print))
cat("transform the op\n")
dt.pred.valid.op <- as.data.table(sapply(ls.pred.valid.op, print))
dt.pred.test.op <- as.data.table(sapply(ls.pred.test.op, print))
# cat("transform optCuts\n")
# dt.optCuts <- as.data.table(sapply(ls.optCuts, print))
dt.pred.train
dt.pred.valid
dt.pred.test
dt.pred.valid.op
dt.pred.test.op
dt.optCuts
cat("median combine the preds\n")
pred.train.final <- apply(dt.pred.valid, 1, function(x) median(x))
pred.valid.final <- apply(dt.pred.valid, 1, function(x) median(x))
pred.test.final <- apply(dt.pred.test, 1, function(x) median(x))
pred.valid.final.op <- apply(dt.pred.valid.op, 1, function(x) median(x))
pred.test.final.op <- apply(dt.pred.test.op, 1, function(x) median(x))
# cat("median combine the opCuts")
# opCuts.final <- apply(dt.optCuts, 1, function(x) median(x))
# cat("apply opCuts on pred.valid.final")
# cuts.valid.final <- c(min(pred.valid.final), opCuts.final, max(pred.valid.final))
# pred.valid.final.op <- as.integer(pred.valid.final, opCuts.final)
cat("check the score")
score <- ScoreQuadraticWeightedKappa(y.valid, round(pred.valid.final.op))
score
submission = data.table(Id = dt.test$Id)
submission$Response = round(pred.test.final.op)
table(submission$Response)
write.csv(submission, "submit/049_try_again.csv", row.names = FALSE) # 0.6574313 (LB 0.67426) *
dt.optCuts <- as.data.table(sapply(ls.optCuts, print))
cat("transform score\n")
dt.score <- as.data.table(sapply(ls.score, print))
core.blend <- as.data.table()
for (xx in 1:15){
score.blend[xx] <- dt.pred.valid.op[, xx, with = F] * as.numeric(dt.score[xx])
}
dt.score.blend <- as.data.table(sapply(score.blend, print))
dt.test.try <- round(rowSums(dt.score.blend) / sum(dt.score))
score.blend <- data.table()
for (xx in 1:15){
score.blend[xx] <- dt.pred.valid.op[, xx, with = F] * as.numeric(dt.score[xx])
}
dt.pred.valid.op
class(dt.pred.valid.op)
score.blend <- list()
for (xx in 1:15){
score.blend[xx] <- dt.pred.valid.op[, xx, with = F] * as.numeric(dt.score[xx])
}
dt.score.blend <- as.data.table(sapply(score.blend, print))
dt.test.try <- round(rowSums(dt.score.blend) / sum(dt.score))
ScoreQuadraticWeightedKappa(y.valid, round(dt.valid.try))
ScoreQuadraticWeightedKappa(y.valid, round(dt.test.try))
score.blend <- list()
for (xx in 1:15){
score.blend[xx] <- pred.test.final.op[, xx, with = F] * as.numeric(dt.score[xx])
}
dt.score.blend <- as.data.table(sapply(score.blend, print))
dt.test.try <- round(rowSums(dt.score.blend) / sum(dt.score))
pred.test.final.op
score.blend <- list()
for (xx in 1:15){
score.blend[xx] <- dt.pred.test.op[, xx, with = F] * as.numeric(dt.score[xx])
}
dt.score.blend <- as.data.table(sapply(score.blend, print))
dt.test.try <- round(rowSums(dt.score.blend) / sum(dt.score))
dt.test.try
pred.test.final.op <- dt.pred.test.op
submission = data.table(Id = dt.test$Id)
submission$Response = round(pred.test.final.op)
table(submission$Response)
length(dt.test.try)
pred.test.final.op <- dt.test.try
submission = data.table(Id = dt.test$Id)
submission$Response = round(pred.test.final.op)
table(submission$Response)
write.csv(submission, "submit/050_try_blend_again.csv", row.names = FALSE) # 0.6574313 (LB 0.67426) *
highest <- fread("submit/028_xgb_poisson_recv_feval_08trai02valid_with_impute_1_and_all_engineed_features_with_dummy_vars_with_08percent_optcuts_with_product_2_num_and_product_2_1_without_group_features_min_child_weight_100_tsne.csv")
highest
genetic <- fread("benchmark_script/gptest.csv")
genetic
blender <- round(highest$Response *.8 + genetic * .2)
newSubt <- data.table(highest$Id, Response = blender)
newSubmit <- data.table(highest$Id, Response = blender)
newSubmit
blender <- round(highest$Response *.8 + genetic$Response * .2)
newSubmit <- data.table(highest$Id, Response = blender)
newSubmit
blender <- round(highest$Response *.8 + genetic$Response * .2)
newSubmit <- data.table(Id = highest$Id, Response = blender)
newSubmit
table(genetic$Response, highest$Response)
newSubmit
highest
overfit <- fread("benchmark_script/xgb_offset_submission_2.csv")
table(overfit$Response, highest$Response)
linear <- fread("benchmark_script/linear.csv")
plot(highest$Response, linear$Response)
plot(head(highest$Response, 100), head(linear$Response, 100))
table(newSubmit$Response)
highest <- fread("submit/028_xgb_poisson_recv_feval_08trai02valid_with_impute_1_and_all_engineed_features_with_dummy_vars_with_08percent_optcuts_with_product_2_num_and_product_2_1_without_group_features_min_child_weight_100_tsne.csv")
genetic <- fread("benchmark_script/gptest.csv")
overfit <- fread("benchmark_script/xgb_offset_submission_2.csv")
linear <- fread("benchmark_script/linear.csv")
blender <- round(highest$Response *.8 + genetic$Response * .2)
newSubmit <- data.table(Id = highest$Id, Response = blender)
table(newSubmit$Response)
table(highest$Response)
table(genetic$Response)
head(highest$Response)
head(genetic$Response)
head(blender)
table(overfit$Response)
table(linear$Response)
table(newSubmit$Response)
write.csv(submission, "submit/051_blend_test_highest_genetic.csv", row.names = FALSE) # 0.6574313 (LB 0.67426) *
table(highest$Response)
table(genetic$Response)
blender <- round(highest$Response *.7
+ genetic$Response * .1
+ linear$Response * .2)
newSubmit <- data.table(Id = highest$Id, Response = blender)
head(submission)
head(newSubmit)
write.csv(newSubmit, "submit/051_blend_test_highest_genetic.csv", row.names = FALSE) # 0.6574313 (LB 0.67426) *
table(newSubmit$Response)
blender <- round(highest$Response *.8 + genetic$Response * .2) # 0.67300
write.csv(newSubmit, "submit/051_blend_test_highest_genetic.csv", row.names = FALSE) # 0.6574313 (LB 0.67426) *
table(newSubmit$Response)
newSubmit <- data.table(Id = highest$Id, Response = blender)
table(newSubmit$Response)
write.csv(newSubmit, "submit/051_blend_test_highest_genetic.csv", row.names = FALSE) # 0.6574313 (LB 0.67426) *
blender <- round(highest$Response *.7 + linear$Response * .3)
newSubmit <- data.table(Id = highest$Id, Response = blender)
table(newSubmit$Response)
blender <- round(highest$Response *.9 + linear$Response * .1)
newSubmit <- data.table(Id = highest$Id, Response = blender)
table(newSubmit$Response)
write.csv(newSubmit, "submit/052_blend_test_highest_linear.csv", row.names = FALSE) # 0.6574313 (LB 0.67426) *
head(newSubmit)
table(newSubmit$Response)
blender <- round(highest$Response *.7 + overfit$Response * .3)
newSubmit <- data.table(Id = highest$Id, Response = blender)
table(newSubmit$Response)
blender <- round(highest$Response *.5 + overfit$Response * .5)
newSubmit <- data.table(Id = highest$Id, Response = blender)
table(newSubmit$Response)
write.csv(newSubmit, "submit/053_blend_test_highest_overfit.csv", row.names = FALSE) # 0.6574313 (LB 0.67426) *
table(newSubmit$Response)
blender <- round(highest$Response *.9 + overfit$Response * .1)
newSubmit <- data.table(Id = highest$Id, Response = blender)
table(newSubmit$Response)
blender <- round(highest$Response *.8 + genetic$Response * .2) # 0.64025
newSubmit <- data.table(Id = highest$Id, Response = blender)
table(newSubmit$Response)
blender <- round(highest$Response *.9 + linear$Response * .1) # 0.66006
newSubmit <- data.table(Id = highest$Id, Response = blender)
table(newSubmit$Response)
blender <- round(highest$Response *.9 + overfit$Response * .1)
newSubmit <- data.table(Id = highest$Id, Response = blender)
table(newSubmit$Response)
write.csv(newSubmit, "submit/054_blend_test_9highest_1overfit.csv", row.names = FALSE) # 0.6574313 (LB 0.67426) *
